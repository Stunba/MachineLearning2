{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torchtext import data\nfrom torchtext import datasets\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.tensorboard import SummaryWriter","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\nLABEL = data.LabelField(dtype = torch.float)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\nprint(f'Number of training examples: {len(train_data)}')\nprint(f'Number of testing examples: {len(test_data)}')","execution_count":4,"outputs":[{"output_type":"stream","text":"downloading aclImdb_v1.tar.gz\n","name":"stdout"},{"output_type":"stream","text":"aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 33.5MB/s]\n","name":"stderr"},{"output_type":"stream","text":"Number of training examples: 25000\nNumber of testing examples: 25000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(vars(train_data.examples[0]))","execution_count":5,"outputs":[{"output_type":"stream","text":"{'text': ['Clint', 'Eastwood', 'would', 'star', 'again', 'as', 'the', 'battle', '-', 'weary', 'Detective', 'Harry', 'Callahan', ',', 'but', 'would', 'also', 'direct', 'the', 'fourth', 'entry', 'in', 'the', \"'\", 'Dirty', 'Harry', \"'\", 'series', '.', \"'\", 'Sudden', 'Impact', \"'\", 'again', 'like', 'the', 'other', 'additions', ',', 'brings', 'its', 'own', 'distinguishable', 'style', 'and', 'tone', ',', 'but', 'if', 'anything', 'it', \"'s\", 'probably', 'the', 'most', 'similar', 'to', 'the', 'original', 'in', 'it', \"'s\", 'darker', 'and', 'seedy', 'moments', '(', 'and', 'bestowing', 'a', 'classic', 'line', '\"', 'Go', 'ahead', '.', 'Make', 'my', 'day', '\"', ')', '\\x85 ', 'but', 'some', 'of', 'its', 'humor', 'has', 'to', 'been', 'seen', 'to', 'believe', '.', 'A', 'bulldog', '\\x85 ', 'named', 'meathead', 'that', 'pisses', 'and', 'farts', '.', 'Oh', 'yeah', '.', 'However', 'an', 'interesting', 'fact', 'this', 'entry', 'was', 'only', 'one', 'in', 'series', 'to', 'not', 'have', 'it', 'set', 'entirely', 'in', 'San', 'Francisco.<br', '/><br', '/>The', 'story', 'follows', 'that', 'of', 'detective', 'Callahan', 'trying', 'to', 'put', 'the', 'pieces', 'together', 'of', 'a', 'murder', 'where', 'the', 'victim', 'was', 'shot', 'in', 'the', 'groin', 'and', 'then', 'between', 'the', 'eyes', '.', 'After', 'getting', 'in', 'some', 'trouble', 'with', 'office', 'superiors', 'and', 'causing', 'a', 'stir', 'which', 'has', 'some', 'crime', 'lord', 'thugs', 'after', 'his', 'blood', '.', 'He', \"'s\", 'ordered', 'to', 'take', 'leave', ',', 'but', 'it', 'falls', 'into', 'a', 'working', 'one', 'where', 'he', 'heads', 'to', 'a', 'coastal', 'town', 'San', 'Paulo', ',', 'where', 'a', 'murder', 'has', 'occurred', 'similar', 'in', 'vein', '(', 'bullet', 'to', 'groin', 'and', 'between', 'eyes', ')', 'to', 'his', 'case', '.', 'There', 'he', 'begins', 'to', 'dig', 'up', 'dirt', ',', 'which', 'leads', 'to', 'the', 'idea', 'of', 'someone', 'looking', 'for', 'revenge.<br', '/><br', '/>To', 'be', 'honest', ',', 'I', 'was', \"n't\", 'all', 'that', 'crash', 'hot', 'on', 'Eastwood', \"'s\", 'take', ',', 'but', 'after', 'many', 'repeat', 'viewings', 'it', 'virtually', 'has', 'grown', 'on', 'me', 'to', 'the', 'point', 'of', 'probably', 'being', 'on', 'par', 'with', 'the', 'first', 'sequel', \"'\", 'Magnum', 'Force', \"'\", '.', 'This', 'well', '-', 'assembled', 'plot', 'actually', 'gives', 'Eastwood', 'another', 'angle', 'to', 'work', 'upon', '(', 'even', 'though', 'it', 'feels', 'more', 'like', 'a', 'sophisticated', 'take', 'on', 'the', 'vigilante', 'features', 'running', 'rampant', 'at', 'that', 'time', ')', ',', 'quite', 'literal', 'with', 'something', 'punishing', 'but', 'luridly', 'damaging', '.', 'It', \"'s\", 'like', 'he', \"'s\", 'experimenting', 'with', 'noir', '-', 'thriller', 'touches', 'with', 'character', '-', 'driven', 'traits', 'to', 'help', 'develop', 'the', 'emotionally', 'bubbling', 'and', 'eventual', 'morality', 'framework', '.', 'His', 'use', 'of', 'images', 'is', 'lasting', ',', 'due', 'to', 'its', 'slickly', 'foreboding', 'atmospherics', '.', 'Dark', 'tones', ',', 'brooding', 'lighting', '\\x85 ', 'like', 'the', 'scene', 'towards', 'the', 'end', 'akin', 'to', 'some', 'western', 'showdown', 'of', 'a', 'silhouette', 'figure', '(', 'Harry', 'with', 'his', 'new', '.44', 'automag', 'handgun', ')', 'moving', 'its', 'way', 'towards', 'the', 'stunned', 'prey', 'on', 'the', 'fishing', 'docks', '.', 'It', \"'s\", 'a', 'striking', 'sight', 'that', 'builds', 'fear', '!', 'Mixing', 'the', 'hauntingly', 'cold', 'with', 'plain', 'brutality', 'and', 'dash', 'of', 'humor', '.', 'It', 'seemed', 'to', 'come', 'off', '.', 'A', 'major', 'plus', 'with', 'these', 'films', 'are', 'the', 'dialogues', ',', 'while', 'I', 'would', \"n't\", 'call', \"'\", 'Sudden', 'Impact', \"'\", 'first', '-', 'rate', ',', 'it', 'provides', 'ample', 'biting', 'exchanges', 'and', 'memorably', 'creditable', 'lines', '\\x85 ', '\"', 'You', \"'re\", 'a', 'legend', 'in', 'your', 'own', 'mind', '\"', '.', 'Do', \"n't\", 'you', 'just', 'love', 'hearing', 'Harry', 'sparking', 'an', 'amusing', 'quip', ',', 'before', 'pulling', 'out', 'his', 'piece', '.', 'The', 'beating', 'action', 'when', 'it', 'occurs', 'is', 'excitingly', 'jarring', 'and', 'intense', '\\x85 ', 'the', 'only', 'way', 'to', 'go', 'and', 'the', 'pacing', 'flies', 'by', 'with', 'little', 'in', 'the', 'way', 'of', 'flat', 'passages', '.', 'Lalo', 'Schfrin', 'would', 'return', 'as', 'composer', '(', 'after', \"'\", 'The', 'Enforcer', '\"', 'had', 'Jerry', 'Fielding', 'scoring', ')', 'bringing', 'a', 'methodical', 'funky', 'kick', ',', 'which', 'still', 'breathed', 'those', 'gloomy', 'cues', 'to', 'a', 'texturally', 'breezy', 'score', 'that', 'clicked', 'from', 'the', 'get', '-', 'go', '.', 'Bruce', 'Surtees', '(', 'an', 'Eastwood', 'regular', ')', 'gets', 'the', 'job', 'behind', 'the', 'camera', '(', 'where', 'he', 'did', 'a', 'piecing', 'job', 'with', \"'\", 'Dirty', 'Harry', \"'\", ')', 'and', 'gives', 'the', 'film', 'plenty', 'of', 'scope', 'by', 'wonderfully', 'framing', 'the', 'backdrops', 'in', 'some', 'impeccable', 'tracking', 'scenes', ',', 'but', 'also', 'instrument', 'edgy', 'angles', 'within', 'those', 'dramatic', 'moments.<br', '/><br', '/>Eastwood', 'as', 'the', 'dinosaur', 'Callahan', 'still', 'packs', 'a', 'punch', ',', 'going', 'beyond', 'just', 'that', 'steely', 'glare', 'to', 'get', 'the', 'job', 'done', 'and', 'probably', 'showing', 'a', 'little', 'more', 'heart', 'than', 'one', 'would', 'expect', 'from', 'a', 'younger', 'Callahan', '.', 'This', 'going', 'by', 'the', 'sudden', 'shift', 'in', 'a', 'plot', 'turn', 'of', 'Harry', \"'s\", 'quest', 'for', 'justice', '\\x85 ', 'by', 'the', 'badge', 'even', 'though', 'he', 'does', \"n't\", 'always', 'agree', 'with', 'it', '.', 'I', 'just', 'found', 'it', 'odd', '\\x85 ', 'a', 'real', 'change', 'of', 'heart', '.', 'Across', 'from', 'him', 'is', 'a', 'stupendous', 'performance', 'by', 'his', 'beau', 'at', 'the', 'time', 'Sondra', 'Locke', '.', 'Her', 'turn', 'of', 'traumatic', 'torment', '(', 'being', 'senselessly', 'raped', 'along', 'with', 'her', 'younger', 'sister', ')', ',', 'is', 'hidden', 'by', 'a', 'glassily', 'quiet', 'intensity', '.', 'When', 'the', 'anger', 'is', 'released', ',', 'it', \"'s\", 'tactically', 'accurate', 'in', 'its', 'outcome', '.', 'Paul', 'Drake', 'is', 'perfectly', 'menacing', 'and', 'filthy', 'as', 'one', 'of', 'the', 'targeted', 'thugs', 'and', 'Audrie', 'J.', 'Neenan', 'nails', 'down', 'a', 'repellently', 'scummy', 'and', 'big', '-', 'mouthed', 'performance', '.', 'These', 'people', 'are', 'truly', 'an', 'ugly', 'bunch', 'of', 'saps', '.', 'Pat', 'Hingle', 'is', 'sturdy', 'as', 'the', 'Chief', 'of', 'the', 'small', 'coastal', 'town', '.', 'In', 'smaller', 'parts', 'are', 'Bradford', 'Dillman', 'and', 'the', 'agreeably', 'potent', 'Albert', 'Popwell', '(', 'a', 'regular', 'in', 'the', 'series', '1', '-', '4', ',', 'but', 'under', 'different', 'characters', ')', '.', 'How', 'can', 'you', 'forget', 'him', 'in', \"'\", 'Dirty', 'Harry', \"'\", '\\x85 ', 'yes', 'he', 'is', 'bank', 'robber', 'that', \"'s\", 'at', 'the', 'end', 'of', 'the', 'trademark', 'quote', '\"', 'Do', 'I', 'feel', 'lucky', '?', 'Well', ',', 'do', 'ya', ',', 'punk', '?', '\"'], 'label': 'pos'}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, valid_data = train_data.split()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of training examples: {len(train_data)}')\nprint(f'Number of validation examples: {len(valid_data)}')","execution_count":7,"outputs":[{"output_type":"stream","text":"Number of training examples: 17500\nNumber of validation examples: 7500\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 25000\n\nTEXT.build_vocab(train_data, max_size = vocab_size)\nLABEL.build_vocab(train_data)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT.vocab.freqs.most_common(20)","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"[('the', 204019),\n (',', 193654),\n ('.', 166331),\n ('and', 110329),\n ('a', 110150),\n ('of', 101409),\n ('to', 94242),\n ('is', 76799),\n ('in', 61400),\n ('I', 54426),\n ('it', 54053),\n ('that', 49499),\n ('\"', 44109),\n (\"'s\", 43703),\n ('this', 42479),\n ('-', 37154),\n ('/><br', 36011),\n ('was', 35256),\n ('as', 30408),\n ('with', 30268)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT.vocab.itos[:10]","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ndevice = 'cuda'\n\ntrain_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n    (train_data, valid_data, test_data), \n    batch_size = batch_size,\n    device = device\n)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(TEXT.vocab)\nembedding_size = 100\nhidden_size = 256\noutput_size = 1\nlearning_rate = 0.001\npad_idx = TEXT.vocab.stoi[TEXT.pad_token]","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, n_layers=2, \n                 bidirectional=True, dropout=0.5):\n        \n        super().__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n        \n        self.rnn = nn.LSTM(embedding_dim, \n                           hidden_dim, \n                           num_layers=n_layers, \n                           bidirectional=bidirectional, \n                           dropout=dropout)\n        \n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, text, text_lengths):\n        \n        #text = [sent len, batch size]\n        \n        embedded = self.dropout(self.embedding(text))\n        \n        #embedded = [sent len, batch size, emb dim]\n        \n        #pack sequence\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n        \n        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n        \n        #unpack sequence\n        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n\n        #output = [sent len, batch size, hid dim * num directions]\n        #output over padding tokens are zero tensors\n        \n        #hidden = [num layers * num directions, batch size, hid dim]\n        #cell = [num layers * num directions, batch size, hid dim]\n        \n        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n        #and apply dropout\n        \n        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n                \n        #hidden = [batch size, hid dim * num directions]\n            \n        return self.fc(hidden)\n\nmodel = RNN(input_size, embedding_size, hidden_size, output_size, pad_idx)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nlogs_writer = SummaryWriter(log_dir='./logs/rnn')\ncriterion = nn.BCEWithLogitsLoss()","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)\ncriterion = criterion.to(device)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\ndef binary_accuracy(preds, y):\n    \"\"\"\n    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n    \"\"\"\n\n    #round predictions to the closest integer\n    rounded_preds = torch.round(torch.sigmoid(preds))\n    correct = (rounded_preds == y).float() #convert into float for division \n    acc = correct.sum() / len(correct)\n    return acc\n\n\ndef _train(model, iterator, optimizer, criterion, logs_writer, epoch):\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.train()\n    \n    for i, batch in enumerate(iterator):\n        optimizer.zero_grad()\n                \n        text, text_lengths = batch.text\n        predictions = model(text, text_lengths).squeeze(1)\n        loss = criterion(predictions, batch.label)\n        acc = binary_accuracy(predictions, batch.label)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        logs_writer.add_scalar('Itearation Loss/train', loss, epoch*len(iterator) + i)\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n\ndef evaluate(model, iterator, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n    \n        for batch in iterator:\n\n            text, text_lengths = batch.text\n            predictions = model(text, text_lengths).squeeze(1)\n            \n            loss = criterion(predictions, batch.label)\n            \n            acc = binary_accuracy(predictions, batch.label)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n\n\ndef train(model, train_iterator, val_iterator, optimizer, criterion, logs_writer, num_epochs):\n    for epoch in tqdm(range(num_epochs)):\n        train_loss, train_acc = _train(model, train_iterator, optimizer, criterion, logs_writer, epoch)\n        valid_loss, valid_acc = evaluate(model, val_iterator, criterion)\n\n        logs_writer.add_scalar('Accuracy/train', train_acc, epoch)\n        logs_writer.add_scalar('Accuracy/validation', valid_acc, epoch)\n        logs_writer.add_scalar('Loss/train', train_loss, epoch)\n        logs_writer.add_scalar('Loss/validation', valid_loss, epoch)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(model, train_iterator, valid_iterator, optimizer, criterion, logs_writer, 5)","execution_count":25,"outputs":[{"output_type":"stream","text":"100%|██████████| 5/5 [11:03<00:00, 132.71s/it]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = evaluate(model, test_iterator, criterion)\n\nprint(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","execution_count":27,"outputs":[{"output_type":"stream","text":"Test Loss: 0.482 | Test Acc: 77.93%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchtext.vocab import GloVe\n# build the vocabulary\nembedding_size = 100\nTEXT.build_vocab(train_data, max_size = vocab_size, vectors=GloVe(name='6B', dim=embedding_size))\nLABEL.build_vocab(train_data)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RNN(input_size, embedding_size, hidden_size, output_size, pad_idx)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_embeddings = TEXT.vocab.vectors\n\nprint(pretrained_embeddings.shape)","execution_count":53,"outputs":[{"output_type":"stream","text":"torch.Size([25002, 100])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.embedding.weight.data.copy_(pretrained_embeddings)","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\nunk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n\nmodel.embedding.weight.data[unk_idx] = torch.zeros(embedding_size)\nmodel.embedding.weight.data[pad_idx] = torch.zeros(embedding_size)\n\nprint(model.embedding.weight.data)","execution_count":55,"outputs":[{"output_type":"stream","text":"tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ndevice = 'cuda'\n\ntrain_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n    (train_data, valid_data, test_data), \n    batch_size = batch_size,\n    device = device\n)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(TEXT.vocab)\nhidden_size = 256\noutput_size = 1\nlearning_rate = 0.001","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nlogs_writer = SummaryWriter(log_dir='./logs/glove')\ncriterion = nn.BCEWithLogitsLoss()","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)\ncriterion = criterion.to(device)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(model, train_iterator, valid_iterator, optimizer, criterion, logs_writer, 5)","execution_count":60,"outputs":[{"output_type":"stream","text":"\n\n  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n\n 20%|██        | 1/5 [02:12<08:48, 132.11s/it]\u001b[A\u001b[A\n\n 40%|████      | 2/5 [04:25<06:37, 132.45s/it]\u001b[A\u001b[A\n\n 60%|██████    | 3/5 [06:37<04:24, 132.34s/it]\u001b[A\u001b[A\n\n 80%|████████  | 4/5 [08:51<02:12, 132.91s/it]\u001b[A\u001b[A\n\n100%|██████████| 5/5 [11:06<00:00, 133.23s/it]\u001b[A\u001b[A\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = evaluate(model, test_iterator, criterion)\n\nprint(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","execution_count":61,"outputs":[{"output_type":"stream","text":"Test Loss: 0.356 | Test Acc: 87.19%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNN2(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, n_layers=2, \n                 bidirectional=True, dropout=0.5):\n        \n        super().__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n        \n        self.rnn = nn.LSTM(embedding_dim, \n                           hidden_dim, \n                           num_layers=n_layers, \n                           bidirectional=bidirectional, \n                           dropout=dropout)\n        \n        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, text, text_lengths):\n        \n        #text = [sent len, batch size]\n        \n        embedded = self.dropout(self.embedding(text))\n        \n        #embedded = [sent len, batch size, emb dim]\n        \n        #pack sequence\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n        \n        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n        \n        #unpack sequence\n        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n\n        #output = [sent len, batch size, hid dim * num directions]\n        #output over padding tokens are zero tensors\n        \n        #hidden = [num layers * num directions, batch size, hid dim]\n        #cell = [num layers * num directions, batch size, hid dim]\n        \n        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n        #and apply dropout\n        \n        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n                \n        #hidden = [batch size, hid dim * num directions]\n        \n        hidden = self.fc1(hidden)\n        return self.fc2(hidden)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RNN2(input_size, embedding_size, hidden_size, output_size, pad_idx)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_embeddings = TEXT.vocab.vectors\nmodel.embedding.weight.data.copy_(pretrained_embeddings)\n\npad_idx = TEXT.vocab.stoi[TEXT.pad_token]\nunk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n\nmodel.embedding.weight.data[unk_idx] = torch.zeros(embedding_size)\nmodel.embedding.weight.data[pad_idx] = torch.zeros(embedding_size)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nlogs_writer = SummaryWriter(log_dir='./logs/rnn-additional_fc')\ncriterion = nn.BCEWithLogitsLoss()","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)\ncriterion = criterion.to(device)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(model, train_iterator, valid_iterator, optimizer, criterion, logs_writer, 5)","execution_count":68,"outputs":[{"output_type":"stream","text":"\n\n  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A","name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"Given groups=1, weight of size 32 32 3, expected input[916, 28, 100] to have 32 channels, but got 28 channels instead","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-042bcd00e41b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-82eb9544dd3d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_iterator, val_iterator, optimizer, criterion, logs_writer, num_epochs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-82eb9544dd3d>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(model, iterator, optimizer, criterion, logs_writer, epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-62-6c2cecdd4514>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_lengths)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#embedded = [sent len, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 32 32 3, expected input[916, 28, 100] to have 32 channels, but got 28 channels instead"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = evaluate(model, test_iterator, criterion)\n\nprint(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":4}